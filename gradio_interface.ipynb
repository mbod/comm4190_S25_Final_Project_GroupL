{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0f0ffe7-0c06-4656-8d10-4d71170c8f4b",
   "metadata": {},
   "source": [
    "# Gradio UI\n",
    "A simple Gradio UI where a database that holds the reciept json data is saved and queried on using a simple LLM chat UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "862a2796-3308-4bcb-a4d7-e9b4bf69543d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup\n",
    "\n",
    "import os\n",
    "import base64\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import sqlite3\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f4d52a4-2039-42d9-bca4-c6403f6040a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 17 rows into pantry.db.\n"
     ]
    }
   ],
   "source": [
    "# 1. Path to JSON export from your main pipeline\n",
    "JSON_PATH = \"receipt_output.json\"\n",
    "\n",
    "# 2. Connect to (or create) a local SQLite database file\n",
    "DB_PATH = \"pantry.db\"\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# 3. Create a table for receipt items (drop if exists for fresh start)\n",
    "cursor.execute(\"\"\"\n",
    "DROP TABLE IF EXISTS items;\n",
    "\"\"\")\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE items (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    item TEXT NOT NULL,\n",
    "    quantity INTEGER NOT NULL,\n",
    "    expiration DATE,\n",
    "    category TEXT,\n",
    "    location TEXT,\n",
    "    cost REAL\n",
    ");\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "# 4. Read JSON and bulk-insert into the database\n",
    "with open(JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "rows = [\n",
    "    (\n",
    "        d[\"item\"],\n",
    "        d.get(\"quantity\", 1),\n",
    "        None if d.get(\"expiration\") == \"N/A\" else d[\"expiration\"],\n",
    "        d.get(\"category\"),\n",
    "        d.get(\"location\"),\n",
    "        None if d.get(\"cost\") == \"N/A\" else d[\"cost\"],\n",
    "    )\n",
    "    for d in data\n",
    "]\n",
    "\n",
    "cursor.executemany(\"\"\"\n",
    "INSERT INTO items (item, quantity, expiration, category, location, cost)\n",
    "VALUES (?, ?, ?, ?, ?, ?);\n",
    "\"\"\", rows)\n",
    "conn.commit()\n",
    "\n",
    "print(f\"Loaded {len(rows)} rows into {DB_PATH}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7371802-72b2-421b-a07a-b6bf69833e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_pantry_db(sql_query: str) -> list:\n",
    "    \"\"\"Run a SQL query against the local SQLite DB and return rows as dicts.\"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    conn.row_factory = sqlite3.Row\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql_query)\n",
    "    results = [dict(row) for row in cur.fetchall()]\n",
    "    conn.close()\n",
    "    return results\n",
    "\n",
    "def ask_pantry(question: str) -> str:\n",
    "    # 1) Spin up the same OpenAI client you used elsewhere\n",
    "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "    # 2) Pull in your pantry rows\n",
    "    items = query_pantry_db(\"SELECT * FROM items;\")\n",
    "\n",
    "    # 3) Build the prompt\n",
    "    prompt = (\n",
    "        \"You are an expert kitchen assistant with access to my pantry database.\\n\"\n",
    "        \"Here is the current data:\\n\"\n",
    "        f\"{json.dumps(items, indent=2)}\\n\\n\"\n",
    "        f\"User question: {question}\\n\"\n",
    "        \"Answer concisely based on the data above.\"\n",
    "    )\n",
    "\n",
    "    # 4) Call the same chat API surface you used before\n",
    "    chat = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.0,\n",
    "        max_tokens=300,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    # 5) Return the assistant‚Äôs text\n",
    "    return chat.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e9c81ee-f22e-43a9-8c7f-9f860f7e4e73",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot find empty port in range: 7860-7860. You can specify a different port by setting the GRADIO_SERVER_PORT environment variable or passing the `server_port` parameter to `launch()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 24\u001b[0m\n\u001b[1;32m     12\u001b[0m app \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mInterface(\n\u001b[1;32m     13\u001b[0m     fn\u001b[38;5;241m=\u001b[39mgradio_interface,\n\u001b[1;32m     14\u001b[0m     inputs\u001b[38;5;241m=\u001b[39mgr\u001b[38;5;241m.\u001b[39mTextbox(lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, placeholder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat do I have in my pantry?\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     css\u001b[38;5;241m=\u001b[39mcss,\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# bind to 0.0.0.0 so your browser (and cloud IDE) can see it,\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# and create a public link in case localhost is blocked.\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0.0.0.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_port\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7860\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshare\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# <-- spins up a public URL\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43minbrowser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# <-- tries to auto-open in your default browser\u001b[39;49;00m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/jupyterhub/share/jupyter/venv/python3-12_comm4190/lib/python3.12/site-packages/gradio/blocks.py:2514\u001b[0m, in \u001b[0;36mBlocks.launch\u001b[0;34m(self, inline, inbrowser, share, debug, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, height, width, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, allowed_paths, blocked_paths, root_path, app_kwargs, state_session_capacity, share_server_address, share_server_protocol, auth_dependency, max_file_size, enable_monitoring, strict_cors, node_server_name, node_port, ssr_mode, pwa, _frontend)\u001b[0m\n\u001b[1;32m   2506\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2507\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m http_server\n\u001b[1;32m   2509\u001b[0m     (\n\u001b[1;32m   2510\u001b[0m         server_name,\n\u001b[1;32m   2511\u001b[0m         server_port,\n\u001b[1;32m   2512\u001b[0m         local_url,\n\u001b[1;32m   2513\u001b[0m         server,\n\u001b[0;32m-> 2514\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43mhttp_server\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_server\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_port\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_port\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mssl_keyfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssl_keyfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mssl_certfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssl_certfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mssl_keyfile_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssl_keyfile_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2521\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver_name \u001b[38;5;241m=\u001b[39m server_name\n\u001b[1;32m   2523\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocal_url \u001b[38;5;241m=\u001b[39m local_url\n",
      "File \u001b[0;32m/opt/jupyterhub/share/jupyter/venv/python3-12_comm4190/lib/python3.12/site-packages/gradio/http_server.py:156\u001b[0m, in \u001b[0;36mstart_server\u001b[0;34m(app, server_name, server_port, ssl_keyfile, ssl_certfile, ssl_keyfile_password)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find empty port in range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmin\u001b[39m(server_ports)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmax\u001b[39m(server_ports)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. You can specify a different port by setting the GRADIO_SERVER_PORT environment variable or passing the `server_port` parameter to `launch()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m     )\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ssl_keyfile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     path_to_local_server \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl_host_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mport\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot find empty port in range: 7860-7860. You can specify a different port by setting the GRADIO_SERVER_PORT environment variable or passing the `server_port` parameter to `launch()`."
     ]
    }
   ],
   "source": [
    "# Cell #3: simple Gradio app to ask questions of your digital pantry\n",
    "import gradio as gr\n",
    "\n",
    "def gradio_interface(user_question):\n",
    "    return ask_pantry(user_question)\n",
    "\n",
    "css = \"\"\"\n",
    "/* optional: center content */\n",
    ".gradio-container { max-width: 800px; margin: auto; }\n",
    "\"\"\"\n",
    "\n",
    "app = gr.Interface(\n",
    "    fn=gradio_interface,\n",
    "    inputs=gr.Textbox(lines=2, placeholder=\"What do I have in my pantry?\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"üçé Pang: Digital Pantry Assistant\",\n",
    "    description=\"Ask questions like 'What fruit do I have?' or 'List items expiring soon.'\",\n",
    "    css=css,\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # bind to 0.0.0.0 so your browser (and cloud IDE) can see it,\n",
    "    # and create a public link in case localhost is blocked.\n",
    "    app.launch(\n",
    "        server_name=\"0.0.0.0\",\n",
    "        server_port=7860,\n",
    "        share=True,       # <-- spins up a public URL\n",
    "        inbrowser=True    # <-- tries to auto-open in your default browser\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
